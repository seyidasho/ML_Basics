---
title: "Anomaly Detection"
author: "Seyi Dasho"
date: December 6 2023
format:
  html:
    code-fold: true
jupyter: python3
---

**Anomaly/outlier detection**<br>
i.	Anomaly detection refers to identifying rare items, events or observations that are significantly different from the majority of the data. These outliers or anomalies may be indicative of some issue or abnormal behavior.<br>
ii.	Goal is to detect anomalies with high accuracy while minimizing false positives.<br>
iii.	Applications include fraud detection, network intrusion, breakdown detection in manufacturing, etc.<br>
**Common approaches:** <br>
i.	Statistical methods: Declare points outliers if they are far from mean/median or in the tails of a distribution.<br>
ii.	Distance-based: Find points with low nearest neighbor density as outliers.<br>
iii.	Classification-based: Train binary classifiers to distinguish between normal and outlier classes.<br>
iv.	Clustering: Identify small clusters or points far from clusters as anomalous.<br>

•	Unsupervised methods like statistical metrics, isolation forests and local outlier factor do not require labeled data.<br>
•	Supervised models like SVM, neural networks can be trained if labeled examples of anomalies exist.<br>
•	Key challenges are class imbalance (far more normal points than anomalies), obtaining labels, and defining anomalies for complex data.<br>
•	Evaluation metrics include precision, recall, F1-score. Cross-validation helps avoid overfitting.<br>
•	Overall, anomaly detection is critical for identifying irregularities, errors, novelties and outliers that could indicate important events or issues.<br>

**Example using Local Outlier Factor**

```{python}
#| tags: []
from sklearn.neighbors import LocalOutlierFactor
import numpy as np
import matplotlib.pyplot as plt

# Generate sample data
X = 0.3 * np.random.randn(100, 2)
X = np.r_[X + 2, X - 2]

# 

# Fit LOF model
clf = LocalOutlierFactor()
y_pred = clf.fit_predict(X)

# Identify outliers
outlier_idx = np.where(y_pred == -1)

# Plot data
plt.scatter(X[:,0], X[:,1], s=50)
plt.scatter(X[outlier_idx,0], X[outlier_idx,1], color='r', s=100)
plt.title("Local Outlier Factor")
plt.show()
```

•	This fits a LOF model to randomly generated sample data, makes predictions to identify outliers, and plots the outliers in red.<br>
•	LOF is an unsupervised anomaly detection method that works well with low dimensional data. The key steps - fit model, predict outliers, evaluate results - demonstrate the basic workflow for applying anomaly detection in Python.<br>

**Example using Isolation Forest**

```{python}
#| tags: []
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_wine
from sklearn.ensemble import IsolationForest
from sklearn.metrics import precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')
# Load the wine dataset from Scikit-learn
wine = load_wine()
X = wine.data
y = wine.target

# Add outliers to the dataset (for demonstration purposes)
outliers = np.array([[14, 2, 2, 80, 1, 3, 1, 1, 5, 1, 1, 1, 1000],  # Adding an outlier to the first sample
                    [12, 1, 2, 10, 2, 2, 1, 2, 3, 1, 2, 1, 50]])  # Adding an outlier to the second sample
X_with_outliers = np.vstack([X, outliers])
y_with_outliers = np.concatenate([y, [-1, -1]])  # Adding labels for outliers

# Fit the Isolation Forest model
model = IsolationForest(contamination=0.05)  # Adjust the contamination parameter as needed
model.fit(X_with_outliers)

# Predict anomalies
predictions = model.predict(X_with_outliers)

# Evaluate the model
precision = precision_score(y_with_outliers, predictions, pos_label=-1, average='weighted')
recall = recall_score(y_with_outliers, predictions, pos_label=-1, average='weighted')
f1 = f1_score(y_with_outliers, predictions, pos_label=-1, average='weighted')

print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')
print(f'F1 Score: {f1:.2f}')
```

```{python}
#| tags: []
# Plot the results
plt.figure(figsize=(10, 6))

# Plot normal data points
plt.scatter(X[:, 0], X[:, 1], c='blue', label='Normal Data')

# Plot outliers
plt.scatter(outliers[:, 0], outliers[:, 1], c='red', label='Outliers', marker='x', s=100)

# Highlight predicted anomalies
plt.scatter(X_with_outliers[predictions == -1, 0], X_with_outliers[predictions == -1, 1],
            c='yellow', label='Predicted Anomalies', marker='o')

plt.title('Isolation Forest Anomaly Detection on Scikit-learn Wine Data (with Outliers)')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()
```


